{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-Time fMRI Analysis\n",
    "\n",
    "In typical fMRI experiments the researcher creates a sequence of stimuli or events they want to show in advance and then measures the participant's brain activity in response to this pre-specified task. This provides an assessment of the relationship between behavior in the task and BOLD activity. However, although tempting, it is not possible to conclude from this correlation alone that active brain regions are causing the behavior. Such causal inferences have typically required directly intervening to disrupt or enhance the functioning of a brain region (e.g., via stimulation, lesioning, cooling, etc.) and then examining the impact on behavior. Such experimental manipulations of brain function, especially in a regionally specific way, require invasive techniques and so are not possible in healthy humans for ethical reasons.\n",
    "\n",
    "Real-time fMRI is a step in the direction of (safely) manipulating brain regions, enabling more valid causal inferences about the brain and behavior. Specifically, rather than brain activity being just a dependent variable, it becomes part of the experimental design as a kind of independent variable. For more on real-time fMRI, see [here](https://doi.org/10.1177/1073858411407205) or [here](https://www.nature.com/articles/nrn.2016.164).\n",
    "\n",
    "Take for instance a recent study using real-time fMRI to train attention [deBettencourt et al. (2015)](http://ntblab.yale.edu/wp-content/uploads/2015/03/deBettencourt_NN_2015.pdf). In this study, patterns of brain activity were used to make the task easier or harder depending on the participant's attentional state, with the goal of training them to attend better. However, if the brain activity was too noisy or analyzed inappropriately, read out from brain regions that didn't contain information about attentional state, or taken from another participant's brain (as in the control condition), then the participant should not improve.\n",
    "\n",
    "There are no second chances with real-time fMRI because your analysis is part of data collection. For example, you can't later decide to use a different preprocessing step, analysis algorithm, parameter setting, feedback type, etc. This is why preparation, piloting, and efficient code is critical for real-time fMRI. Think of it as mandatory pre-registration!\n",
    "\n",
    "There are many different types of real-time fMRI, but here we focus on using the multivariate methods from earlier notebooks to analyze data on the fly and generate feedback for participants in a closed-loop manner.\n",
    "\n",
    "\n",
    "## Goal of this script\n",
    "    1. Learn to design a multivariate real-time fMRI experiment  \n",
    "    2. Run a real-time fMRI analysis using simulated data  \n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "[1. The real-time workflow](#rt_wf)  \n",
    ">[1.1. Data file preparation](#data_prep)  \n",
    ">[1.2. File watcher](#file-watch)   \n",
    ">[1.3. Preprocessing a volume](#preprocess-tr)  \n",
    ">[1.4. Training a model](#real-time-train)  \n",
    ">[1.5. Classifying new volumes](#real-time-test)  \n",
    ">[1.6. Modifying stimuli for feedback](#mod-stim)  \n",
    "  \n",
    "[2. Running a real-time simulation](#real-time-sim)\n",
    "\n",
    "[3. Adaptive real-time experiments](#real-time-change)\n",
    "\n",
    "\n",
    "Exercises\n",
    ">[1](#ex1)   [2](#ex2)  [3](#ex3)  [4](#ex4)  [5](#ex5)  [6](#ex6)  [7](#ex7)  [8](#ex8)    \n",
    ">[Novel contribution](#novel)   \n",
    "\n",
    "[Contributions](#contributions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The real-time workflow <a id=\"rt_wf\"></a>\n",
    "\n",
    "The following sequence of steps are necessary for successfully running a real-time fMRI analysis. \n",
    "\n",
    "1. [Data file preparation](#data_prep): Setup a folder where fMRI volumes will be stored as they are created.\n",
    "        \n",
    "2. [File watcher](#file-watch): A function that looks for a volume to process.\n",
    "\n",
    "3. [Preprocessing a volume](#preprocess): Preprocess the TR to prepare it for classification.\n",
    "\n",
    "4. [Training a model](#real-time-train): Take the data you have set aside for training and create your classifier model.\n",
    "\n",
    "4. [Classifying new volumes](#real-time-test): Take an epoch of data and classify that, assigning it a label.\n",
    "\n",
    "6. [Modifying stimuli for feedback](#mod-stim) The classifier results influence the next stimulus shown to the participant.\n",
    "\n",
    "Here is an example pipeline from deBettencourt et al. (2015):\n",
    "\n",
    "![alt text](https://media.nature.com/lw926/nature-assets/neuro/journal/v18/n3/images/nn.3940-F1.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np  # type: ignore\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression  # type: ignore\n",
    "from queue import Queue\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "import scipy.stats\n",
    "from IPython import display\n",
    "import shutil\n",
    "from utils import results_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data file preparation <a id=\"data_prep\"></a>\n",
    "\n",
    "As you know, an fMRI data volume is generated for each TR. The scanner outputs these files one-by-one in DICOM format. We will not cover here how to create a network link between your scanner and your analysis computer, but you can find example instructions for Siemens [here](https://yale.box.com/s/ko0geash2en18ksx1ntgz5m71nhe60ld). Once transferred to the analysis computer, you will first need to read the DICOM data into a numpy array. The code below will then process the numpy array. One way to read DICOM files into numpy is by using the package [dicom-numpy](http://dicom-numpy.readthedocs.io/en/latest/).\n",
    "\n",
    "For this notebook, we will generate simulated data using the BrainIAK [fmrism module](http://brainiak.org/docs/brainiak.utils.html?highlight=fmrisim#module-brainiak.utils.fmrisim). The function *generate_data.py* simulates a two condition experiment where each condition is blocked for 10s with no gap between events. This function simulates fMRI noise and then inserts signal in two regions corresponding to the two conditions with the appropriate hemodynamic response function. \n",
    "\n",
    "**Self-Study:** Investigate the *generate_data.py* function to learn how it is working and what brain activity distinguishes between conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:**<a id=\"ex1\"></a> How is *generate_data.py* deciding the order of the two conditions? Is this how you would design an fMRI study? If not, modify the script to what you think is a better design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**A:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simulate real-time data, this function outputs a TR every 2 s and saves it as a numpy matrix in the *fmrisim/data/* folder. To run the script, run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run the generate_data function\n",
    "if shutil.which('sbatch') is not None:\n",
    "    !sbatch ./13-real-time/run_generate_data.sh\n",
    "else:\n",
    "    %run ./13-real-time/generate_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any time you want to simulate the acquisition of data you should delete the contents of this folder (`rm 13-real-time/fmrisim/data/*`) and then run it again.\n",
    "\n",
    "Below we will set the paths to be used. We also want to specify the proportion of trials that will be used for training the model (time until the real-time neurofeedback kicks in)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join(results_path, '13-real-time/data/')  # Where is information stored that is needed for generating data\n",
    "file_pattern = 'rt_{0:0>3}.npy'  # What is the pattern of file that wil be created\n",
    "\n",
    "train_count = 40  # Number of trials that will be used for training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 File watcher <a id=\"file-watch\"></a>\n",
    "\n",
    "For real-time fMRI, we need to monitor as every TR comes in. The simple way to do this is to just set up a loop that checks whether the file exists and waits until it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a file watching algorithm\n",
    "def tr_watcher_simple(filename,\n",
    "                      sleep_time=0.1,  # temporal resolution of the file watcher\n",
    "                     ):\n",
    "    \n",
    "    # While the file doesn't exist, loop and wait\n",
    "    while not os.path.exists(filename):\n",
    "        time.sleep(sleep_time)  # How long do you want to wait for\n",
    "        \n",
    "    # When the file exists, load it and output it\n",
    "    vol = np.load(filename)\n",
    "    \n",
    "    return vol\n",
    "use_simple_watcher = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this procedure is inefficient and prone to error. For instance, if a volume is added just after a check, this code waits the sleep time before checking again. Moreover, this procedure can crash since the file names often exist before the file contents are created.\n",
    "\n",
    "Instead, to process volumes as soon as they are finished being created, a file watcher function continuously polls for new files. Once a new file is found, it is added to a queue and triggers a call to the next processing step. The [watchdog package](https://pythonhosted.org/watchdog/) is used for ths purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a file watching algorithm\n",
    "from watchdog.events import PatternMatchingEventHandler  # type: ignore\n",
    "from watchdog.observers import Observer  # type: ignore\n",
    "\n",
    "def tr_watcher(filename, file_queue):\n",
    "    \n",
    "    # Does the file exist?\n",
    "    file_exists = os.path.exists(filename)\n",
    "    \n",
    "    # While the file doesn't exist, loop and wait\n",
    "    while not file_exists:\n",
    "        \n",
    "        # look for file creation event\n",
    "        event = file_queue.get()\n",
    "        \n",
    "        # If there is an event then save it\n",
    "        if event.src_path == filename:\n",
    "            file_exists = True\n",
    "    \n",
    "    # When the file exists, load it and output it\n",
    "    vol = np.load(filename)\n",
    "    \n",
    "    return vol\n",
    "\n",
    "\n",
    "# Create a class of events for \n",
    "class file_notify_handler(PatternMatchingEventHandler):\n",
    "\n",
    "    # Initialize the object being created\n",
    "    def __init__(self, queue, file_pattern):\n",
    "        super().__init__(patterns=file_pattern)\n",
    "        self.q = queue\n",
    "    \n",
    "    # When an event occurs, put it in the queue\n",
    "    def on_created(self, event):\n",
    "        self.q.put(event)\n",
    "\n",
    "use_simple_watcher = 0 # Only overwrite if you get to the end of the function        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to check out this file watcher in action. Remember to clear your `13-real-time/fmrisim/data` directory and re-launch *run_generate_data.sh*. This script will first play catch up and then print every time a new TR comes in until the training set is acquired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_simple_watcher == 1:\n",
    "\n",
    "    for idx in range(train_count): \n",
    "\n",
    "        # What file name are you going to load\n",
    "        next_filename = data_dir + file_pattern.format(idx) \n",
    "        vol = tr_watcher_simple(next_filename)\n",
    "\n",
    "        # When the file exists, load it and output it\n",
    "        print('Recieved:', next_filename)\n",
    "    \n",
    "else:\n",
    "    file_observer = Observer()\n",
    "    file_queue = Queue()  # type: ignore\n",
    "\n",
    "    # set up the notifications for when a new TR is created\n",
    "    notify_file_pattern = '*.npy'  \n",
    "    file_notify = file_notify_handler(file_queue, [notify_file_pattern])  \n",
    "    file_observer.schedule(file_notify, data_dir, recursive=False)  \n",
    "    file_observer.start()  \n",
    "\n",
    "    for idx in range(train_count): \n",
    "\n",
    "        # What file name are you going to load\n",
    "        next_filename = data_dir + file_pattern.format(idx) \n",
    "        vol = tr_watcher(next_filename, file_queue)\n",
    "\n",
    "        # When the file exists, load it and output it\n",
    "        print('Recieved:', next_filename)\n",
    "\n",
    "    file_observer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Preprocessing a volume <a id=\"preprocess-tr\"></a>\n",
    "\n",
    "As each volume is received, it is necessary to preprocess it prior to analysis. Given the constraint of wanting to do this as close as possible to real-time, you will need to choose steps carefully and decide on the minimal set of steps that provide the most benefit. For example, motion correction, masking, and normalization might be sufficient. The simulator does not generate any motion artifacts so that step is unnecessary in this notebook. Masking is critical because we don't want to feed the model irrelevant features. Normalization in space (as we will do) is easy because each time point can be treated independently; however, normalizing across time is hard since each additional TR will change the mean and SD, and thus the z-values of all preceding TRs. This is a more general consequence of real-time, wherein you know the past but not the future. This also impacts temporal filtering, which must be done with \"causal\" filters. For this reason, procedures for normalizing and filtering over time are still being developed/refined.\n",
    "\n",
    "**Self-study:** Look into normalizing voxels across time. Helpful information is found in [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). For temporal filtering, compare the [filtfilt](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.signal.filtfilt.html) and [lfilter](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.signal.lfilter.html) functions in scipy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** <a id=\"ex2\"></a>  Create a preprocessing function. This function will take in a volume and a mask, perform masking and then z-score the masked voxels in space, and then output a 1-dimensional vector of preprocessed voxels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Insert code here\n",
    "def preprocess_vol(vol, mask):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** <a id=\"ex3\"></a> Do a speed test of the file watcher and preprocessing functions to make sure they complete in less than 1 TR (here 2s). Specifically add to the starter code below appropriate time stamping and print commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Insert code here\n",
    "    \n",
    "# load mask\n",
    "mask_file = data_dir +'mask.npy'\n",
    "mask = np.load(mask_file)\n",
    "\n",
    "# allocate a matrix to hold the TR data, preset to NaNs. Each row is a TR vector\n",
    "tr_data = np.full((train_count, mask.sum()), np.nan)\n",
    "\n",
    "# set up the notifications for when a new TR is created\n",
    "if use_simple_watcher == 0:\n",
    "    file_observer = Observer()\n",
    "    file_queue = Queue()  # type: ignore\n",
    "\n",
    "    notify_file_pattern = '*.npy'  \n",
    "    file_notify = file_notify_handler(file_queue, [notify_file_pattern])  \n",
    "    file_observer.schedule(file_notify, data_dir, recursive=False)  \n",
    "    file_observer.start()  \n",
    "\n",
    "# Cycle through TRs\n",
    "for idx in range(train_count): \n",
    "    \n",
    "    # Start the timer\n",
    "    \n",
    "    # What file name are you going to load\n",
    "    next_filename = data_dir + file_pattern.format(idx) \n",
    "    if use_simple_watcher == 1:\n",
    "        vol = tr_watcher_simple(next_filename)\n",
    "    else:\n",
    "        vol = tr_watcher(next_filename, file_queue)\n",
    "    \n",
    "    # Store the volume as a preprocessed vector\n",
    "    tr_data[idx, :] = preprocess_vol(vol, mask)\n",
    "    \n",
    "    # End the timer\n",
    "    \n",
    "    # Print the timing\n",
    "\n",
    "# Stop the file watcher    \n",
    "if use_simple_watcher == 0:\n",
    "    file_observer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Training a model  <a id=\"real-time-train\"></a>\n",
    "\n",
    "After we have collected enough volumes we then train our classifier. Like [deBettencourt et al. (2015)](http://ntblab.yale.edu/wp-content/uploads/2015/03/deBettencourt_NN_2015.pdf) we will use an L2 regularized logistic regression. Below a function is created to take in time by voxel training data and a list of labels for each volume and then fit a regression function to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train 2 Logistic Regression models\n",
    "def train_logistic(training_data,\n",
    "                   training_labels,\n",
    "                   parameters='l2'):\n",
    "    \n",
    "    # Train the model predicting state 2 (so that true means 1 and false means 0)\n",
    "    clf = LogisticRegression(penalty=parameters)\n",
    "    clf.fit(training_data, training_labels == 2)\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A critical step when training the model is shifting the labels. We expect that a stimulus will evoke activity 4-6 s after its onset because of the hemodynamic lag?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the labels\n",
    "label_file = data_dir + 'labels.npy'\n",
    "labels = np.load(label_file)\n",
    "\n",
    "# How much do you need to shift the labels by in terms of TRs\n",
    "tr_shift = 3\n",
    "\n",
    "training_data   = tr_data[tr_shift:train_count, :]\n",
    "training_labels = labels[0:train_count - tr_shift]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "clf = train_logistic(training_data, training_labels[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now visualize this training in order to see what the model has learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefs = np.zeros(mask.shape)\n",
    "coefs[mask==1]=clf.coef_[0,:]\n",
    "\n",
    "plt.imshow(coefs[:,:,16])\n",
    "plt.title('Classifier coeffients for slice through the brain')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like we mentioned all the way back in notebook 01, it is possible to view these weights using more sophisticated tools such as niwidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Load in the new variable\n",
    "    from niwidgets import NiftiWidget\n",
    "\n",
    "    coefs_nii = nib.Nifti1Image(coefs, np.eye(4))\n",
    "    viewer = NiftiWidget(coefs_nii)\n",
    "    viewer.nifti_plotter();\n",
    "\n",
    "except:\n",
    "    print('niwidgets cannot run, try installing it or some other viewing tool')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Classifying new volumes  <a id=\"real-time-test\"></a>\n",
    "\n",
    "Now that we have trained a model, we can classify incoming volumes with the learned weights. Since most classifiers come with the *.fit* and *.predict* formulation in scikit-learn, this is very easy to do (after some reshaping). In the case of a logistic regression, the outcome is simply `True` or `False`. In this case, `True` means condition 2 and `False` means condition 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get a new volume\n",
    "next_filename = data_dir + file_pattern.format(train_count + 1)\n",
    "vol = tr_watcher(next_filename, file_queue)\n",
    "\n",
    "# Store the volume as a preprocessed vector\n",
    "new_data = preprocess_vol(vol, mask)\n",
    "prediction = clf.predict(new_data.reshape(1, -1))\n",
    "\n",
    "print('Prediction for TR %d is condition %d and the label is %d' % (train_count + 1, prediction + 1, labels[idx - tr_shift]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Modifying stimuli for feedback  <a id=\"mod-stim\"></a>\n",
    "\n",
    "The final step of closed-loop multivariate real-time fMRI is to use the classifier results and provide feedback to the participant in the scanner. This could involve changing the composition of the stimulus, changing the task difficulty, or providing feedback directly via a scale or gauge. Although we won't do this here, such displays can be easily implemented in experiment code from [Psychtoolbox](http://psychtoolbox.org/) or [PsychoPy](http://www.psychopy.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Running a real-time simulation  <a id=\"real-time-sim\"></a>\n",
    "\n",
    "Now that we have all parts of the real-time workflow, we can put them together to run a simulated real-time experiment. The function below named `realtime` does this. \n",
    "\n",
    "This takes as an input the `fmrisim` directory. It also takes the number of volumes that are used for training and a function that specifies how to run the classifier (e.g., `train_logistic`). The final input `incremental_batch` will be discussed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def realtime(data_dir,\n",
    "             train_count,\n",
    "             clf_obj=train_logistic,\n",
    "             incremental_batch=0,\n",
    "            ): \n",
    "        \n",
    "    # While the file doesn't exist, loop and wait\n",
    "    label_file = data_dir + 'labels.npy'\n",
    "    while not os.path.exists(label_file):\n",
    "        time.sleep(0.1)  # How long do you want to wait for\n",
    "    \n",
    "    # load labels\n",
    "    labels = np.load(label_file)\n",
    "\n",
    "    # How much do you need to shift the labels by in terms of TRs\n",
    "    tr_shift = 3\n",
    "    \n",
    "    # load mask\n",
    "    mask_file = data_dir +'mask.npy'\n",
    "    mask = np.load(mask_file)\n",
    "\n",
    "    # allocate a matrix to hold the TR data, preset to NaNs. Each row is a TR vector\n",
    "    tr_data = np.full((len(labels), mask.sum()), np.nan)\n",
    "\n",
    "    # Set up the figure\n",
    "    plt.figure()  # Set up figure\n",
    "    plt.plot((train_count, train_count), (0, 3), 'g')\n",
    "    plt.xlim((0, len(labels)))\n",
    "    plt.ylim((0, 3))\n",
    "    plt.title('Searching for the first TR')\n",
    "    is_print=0\n",
    "    \n",
    "    # set up the notifications for when a new TR is created\n",
    "    if use_simple_watcher == 0:\n",
    "        file_observer = Observer()\n",
    "        file_queue = Queue()  # type: ignore\n",
    "\n",
    "        file_notify = file_notify_handler(file_queue, [notify_file_pattern])  \n",
    "        file_observer.schedule(file_notify, data_dir, recursive=False)  \n",
    "        file_observer.start()  \n",
    "\n",
    "    # Listen for TRs\n",
    "    num_correct = 0  # Preset the number of correct answers to zero\n",
    "    for idx in range(len(labels)): \n",
    "\n",
    "        # What file name are you going to load\n",
    "        next_filename = data_dir + file_pattern.format(idx, '02d')  \n",
    "        \n",
    "        if use_simple_watcher == 1:\n",
    "            vol = tr_watcher_simple(next_filename)\n",
    "        else:\n",
    "            vol = tr_watcher(next_filename, file_queue)\n",
    "\n",
    "        # Store the volume as a preprocessed vector\n",
    "        tr_data[idx, :] = preprocess_vol(vol, mask)\n",
    "\n",
    "        plt.plot(range(idx), labels[0:idx], 'r-')\n",
    "\n",
    "        # Collect TRs for training\n",
    "        if idx < train_count:\n",
    "            plt.title('TR: %d for training' % idx)\n",
    "        elif idx == train_count: # Is this time to train the classifier\n",
    "\n",
    "            # Train the classifier\n",
    "            trainStart = time.time()\n",
    "            plt.title(\"Sufficient TRs collected, training the model\")\n",
    "\n",
    "            # Train the classifier\n",
    "            clf = clf_obj(tr_data[tr_shift:train_count, :], labels[0:train_count - tr_shift][:,0])\n",
    "\n",
    "            # Report the training duration\n",
    "            print(\"Completed training in %0.2f sec\" % (time.time() - trainStart))\n",
    "\n",
    "        elif idx > train_count:  # Is this after training (is it testing)\n",
    "\n",
    "            # Pull out the predictions of the model for this TR\n",
    "            prediction = clf.predict(tr_data[idx, :].reshape(1, -1))\n",
    "\n",
    "            # If it is a boolean (0 or 1) then add 1 to turn it into the labels\n",
    "            if prediction.dtype=='bool':\n",
    "                prediction = prediction + 1\n",
    "\n",
    "            if prediction == labels[idx - tr_shift]:\n",
    "                num_correct += 1\n",
    "\n",
    "            plt.scatter(idx, prediction)\n",
    "            accuracy = num_correct / (idx - train_count)\n",
    "            plt.title('TR: %d; Total accuracy: %0.2f' % (idx + 1, accuracy))\n",
    "\n",
    "            # Do you want to create a new batch for training if doing an incremental fit\n",
    "            if incremental_batch > 0 and np.mod((idx - train_count), incremental_batch) == 0:\n",
    "\n",
    "                # When does this batch start\n",
    "                start_idx = idx - incremental_batch\n",
    "\n",
    "                # Feed in the classifier to be updated with the current batch size\n",
    "                clf = clf_obj(tr_data[start_idx + tr_shift:idx, :], labels[start_idx:idx - tr_shift], clf)\n",
    "\n",
    "                # Mark where the new batch was loaded in\n",
    "                plt.plot((idx, idx), (0, 3), 'k')\n",
    "\n",
    "        # Plot the figure\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        plt.xlim((0, len(labels)))\n",
    "        plt.ylim((0, 3))\n",
    "        \n",
    "    # Stop listening\n",
    "    if use_simple_watcher == 0:\n",
    "        file_observer.stop()\n",
    "    \n",
    "    # Return the accuracy overall\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    realtime(data_dir=data_dir,\n",
    "             train_count=train_count,\n",
    "             clf_obj=train_logistic,\n",
    "             incremental_batch=0,\n",
    "            )\n",
    "except Exception as err:\n",
    "    if use_simple_watcher == 0:\n",
    "        file_observer.stop()\n",
    "    print(\"Exception: {}\".format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4:**<a id=\"ex4\"></a> Re-run the `realtime` function using a different classifier. Create a new classifier function with a different kernel and run it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Insert new classifier object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run the realtime function with this new classifier object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5:**<a id=\"ex5\"></a> Create a new copy of the `realtime` function below and rename it. Then edit it in order to plot the classifier decision evidence rather than the labels. Make sure that you have an appropriate classifier that outputs the decision evidence for each prediction (and re-scale your figure appropriately)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Insert code below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adaptive real-time experiments  <a id=\"real-time-change\"></a>\n",
    "\n",
    "The goal of real-time fMRI is often to change brain function via neurofeedback. For instance, neural representations might change because the experiment trains participants to use different parts of their brain to process a stimulus. In such cases, a classifier trained at the start of the experiment will be wrong by the end of the experiment because the underlying feature space across voxels in the brain has changed. There are algorithms that can be used in these cases, which allow the model fit to be updated incrementally as new training examples come in. This can also be used to refine your model with more training data even if the underlying features are stable. \n",
    "\n",
    "This approach to dynamically training classifiers is called incremental or online learning and [scikit-learn](http://scikit-learn.org/stable/modules/scaling_strategies.html#incremental-learning) has a number of classifiers that allow this. Below we specify one classifier with this functionality. First we will run it without incremental updating as a baseline. \n",
    "\n",
    "Beware: The initialization of these functions can have a dramatic effect on performance, which you can evaluate by using a random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_incremental(training_data,\n",
    "                      training_labels,\n",
    "                      parameters=None,\n",
    "                     ):\n",
    "    \n",
    "    all_classes = np.array([1, 2])  # Need to say all the labels, in case you want to test out of sample\n",
    "    \n",
    "    # Get the clf\n",
    "    if parameters is None:\n",
    "        # Create the linear if it hasn't already been passed in by parameters\n",
    "        clf = linear_model.SGDClassifier()\n",
    "    else:\n",
    "        clf = parameters  # Pull out the classifier\n",
    "        \n",
    "    # Fit the training data (either initializing the clf or updating it)    \n",
    "    clf.partial_fit(training_data,\n",
    "                    training_labels,\n",
    "                    classes=all_classes,\n",
    "                   )\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    np.random.seed(0)\n",
    "    realtime(data_dir=data_dir,\n",
    "             train_count=train_count,\n",
    "             clf_obj=train_incremental,\n",
    "             incremental_batch=0,\n",
    "            )\n",
    "except Exception as err:\n",
    "    if use_simple_watcher == 0:\n",
    "        file_observer.stop()\n",
    "    print(\"Exception: {}\".format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have run the classifier with static weights, we can try dynamically updating the classifier as we acquire more data. This is accomplished by telling `realtime` how often you want to update (here, after every additional 20 TRs). The `incremental_batch` variable specifies how many volumes are used in each batch of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    np.random.seed(0)\n",
    "    realtime(data_dir=data_dir,\n",
    "                   train_count=train_count,\n",
    "                   clf_obj=train_incremental,\n",
    "                   incremental_batch=40,\n",
    "                  )\n",
    "except Exception as err:\n",
    "    if use_simple_watcher == 0:\n",
    "        file_observer.stop()\n",
    "    print(\"Exception: {}\".format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6:**<a id=\"ex6\"></a> Adjust the size of the batch that you use to re-train the model. What are the advantages of using a small vs. large batch? What batch size that you tried works best and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a classifier that can update its weights dynamically, we will perform a simulation in which the responses in the fMRI data change part way through the study. The `generate_data.py` script allows this with a few parameter changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7:**<a id=\"ex7\"></a> Simulate new data where the brain areas that discriminate between conditions switch halfway through the run. Hint: look at the parameters in `generate_data.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8:**<a id=\"ex8\"></a> Run a real-time analysis on this new dataset with and without incremental learning (using the optimal batch size from above) and compare the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take this to the next level by doing a parameter search over the different combinations of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_values = range(10, 100, 10)\n",
    "train_values = range(10, 100, 10)\n",
    "results = np.zeros((len(batch_values), len(train_values)))\n",
    "for batch_counter in range(len(batch_values)):\n",
    "    for train_counter in range(len(train_values)):\n",
    "        \n",
    "        # Pull out the values\n",
    "        batch_size = batch_values[batch_counter]\n",
    "        train_size = train_values[train_counter]\n",
    "        \n",
    "        np.random.seed(0)\n",
    "        result = realtime(data_dir=data_dir,\n",
    "                          train_count=train_size,\n",
    "                          clf_obj=train_incremental,\n",
    "                          incremental_batch=batch_size,\n",
    "                         )\n",
    "\n",
    "        # Store the results\n",
    "        results[batch_counter, train_counter] =  result\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can visualize this parameter search by making a heat map\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.imshow(results, interpolation = 'none')\n",
    "plt.xlabel(\"Incremental batch value\")\n",
    "plt.ylabel(\"# TRs used for training\")\n",
    "plt.title(\"Heatmap of SDG classification accuracy with different input parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Novel contribution:**<a id=\"novel\"></a> Be creative and make one new discovery by adding an analysis, visualization, or optimization.  \n",
    "\n",
    "Here are some ideas:\n",
    "- Build a real-time experiment with more than two classes e.g. for three classes you could use Faces, Places, and Objects.\n",
    "- Use GridSearch to find optimal hyper-parameters in real-time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contributions<a id=\"contributions\"></a>\n",
    "\n",
    "G. Wallace for providing initial code.  \n",
    "M. Kumar, C. Ellis and N. Turk-Browne produced the initial notebook 04/2018.  \n",
    "G. Wallace enabled execution in non cluster environments."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
