{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Inter-Subject Correlation and Inter-Subject Functional Correlation \n",
    "\n",
    "The functional connectivity methods that we used in previous notebooks compared time series of BOLD activity between voxels within participant to infer how different regions of the brain were interacting. However, BOLD activity contains multiple components ([Figure a](#fig1)):\n",
    "1. Task-based/stimulus-evoked signal that is reliable across participants\n",
    "2. Intrinsic fluctuations in neural activity that are participant specific\n",
    "3. Scanner or physiological noise\n",
    "\n",
    "In this notebook, we will consider methods that combine data across participants to eliminate #2 and #3 when calculating fMRI reliability (intersubject correlation, ISC, [Hasson et al., 2004](https://doi.org/10.1126/science.1089506)) and connectivity (intersubject functional correlation, ISFC, [Simony et al., 2016](https://doi.org/10.1038/ncomms12141)). ISC and ISFC help isolate #1 because it is the only component that ought to be shared across participants.\n",
    "\n",
    "[Figure b,c](#fig1) show how ISC differs from functional connectivity: rather than correlating brain regions, which preserves participant-specific activity and noise, ISC correlates between the brains of different participants in order to capture only the activity that is shared. In ISC, this correlation is done for every voxel in the brain to the matching voxel in other brains, producing a full brain map. [Figure e](#fig1) shows this as the diagonal of a correlation matrix, where each cell corresponds to a voxel in subject X correlated with the same anatomical voxel in subject Y. In practice, to simplify the computation and the interpretation it is typical for ISC to compare each individual participant with the average of all other participants.\n",
    "\n",
    "[Figure d](#fig1) shows ISFC: the correlation of every voxel in one participant with every other voxel in another participant (or average of other participants). This is like FCMA except it is between participants rather than within participants. In fact, these analyses use the same computational tricks. ISFC is valuable because it allows us to identify activity coupling in voxels that are not aligned across participants: the off diagonal in [Figure e](#fig1) represents correlations for voxels in different parts of the brain.\n",
    "\n",
    "<a id=\"fig1\"></a>![alt text](https://media.springernature.com/m685/nature-assets/ncomms/2016/160718/ncomms12141/images/ncomms12141-f1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use ISC and ISFC to identify brain regions that respond preferentially to narrative stories, rather than to a random assortment of words (replicating Simony et al., 2016). Furthermore, seed-based connectivity analysis does not show differences between resting state, random words, and intact narratives, but ISFC does distinguish between these conditions (Simony et al., 2016). Thus, ISFC shows greater sensitivity to the task than seed-based functional connectivity. \n",
    "\n",
    "## Goal of this script\n",
    "    1. To run intersubject correlation (ISC).\n",
    "    2. To run intersubject functional correlation (ISFC).  \n",
    "    3. Use ISFC to examine how a network of brain regions that respond to narrative stimuli.  \n",
    " \n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "[1. The ISC-ISFC Workflow](#isc_isfc_wkflow)  \n",
    "\n",
    "[2. ISC](#isc)\n",
    ">[2.1 The \"Pieman\" data](#dataset)  \n",
    ">[2.2 Data file preparation](#data_prep_isc)  \n",
    ">[2.3 Compute ISC](#isc_compute)  \n",
    ">[2.4 ISC with statistical tests](#isc_stats)  \n",
    "\n",
    "[3. ISFC](#isfc)\n",
    ">[3.1 Parcel the data](#isfc_parcel)   \n",
    ">[3.2 Compute FC and ISFC](#fc_isfc)\n",
    "\n",
    "[4. Spatial Correlation](#spat_corr)\n",
    ">[4.1 Spatial inter-subject correlation](#spatial_isc)  \n",
    "\n",
    "#### Exercises\n",
    ">[1](#ex1)   [2](#ex2)  [3](#ex3)  [4](#ex4)  [5](#ex5)  [6](#ex6)  [7](#ex7)  [8](#ex8)   [9](#ex9)  \n",
    ">[Novel contribution](#novel)  \n",
    "\n",
    "[Contributions](#contributions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The ISC-ISFC workflow  <a id=\"isc_isfc_wkflow\"></a>\n",
    "\n",
    "\n",
    "The following sequence of steps are recommended for successfully running ISC and ISFC using [BrainIAK](http://brainiak.org/). \n",
    "\n",
    "1. [**Data Preparation:**](#data_prep_isc) Organize a data directory with fMRI subject data that you want to process. All subjects must be in the same anatomical space for analysis. Also you need to create a whole-brain mask. The outcome of this is an array of anatomically-aligned and temporally-aligned brain data.  \n",
    "        \n",
    "2. [**Compute ISC:**](#isc_compute)  The ISC function computes correlations across subjects for corresponding voxels in the mask. It uses the `compute_correlation` function in BrainIAK, which is optimized for fast execution (and was used in FCMA).\n",
    "\n",
    "3. [**Permutation Test for ISC:**](#isc_stats) Perform statistical analysis to determine significant correlation values for ISC.\n",
    "\n",
    "4. [**Compute ISFC:**](#isfc_compute) The ISFC function computes correlations for every voxel in one subject with every other voxel averaged across subjects.\n",
    "\n",
    "5. [**Cluster the ISFC results:**](#clust_isfc) Create clusters based on the correlation values. \n",
    "\n",
    "6. [**Perform ISFC permutation:**](#perm) Perform permutation tests to determine the significance of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "import os \n",
    "import glob\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from nilearn import datasets\n",
    "from nilearn import surface\n",
    "from nilearn import plotting\n",
    "from nilearn.input_data import NiftiMasker, NiftiLabelsMasker\n",
    "import nibabel as nib\n",
    "\n",
    "from brainiak import image, io\n",
    "from brainiak.isc import isc, isfc, permutation_isc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "%autosave 5\n",
    "%matplotlib inline\n",
    "sns.set(style = 'white', context='talk', font_scale=1, rc={\"lines.linewidth\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ISC  <a id=\"isc\"></a>\n",
    "\n",
    "### 2.1 The \"Pieman\" data  <a id=\"dataset\"></a>\n",
    "\n",
    "For this script we will use the \"Pieman\" dataset from [Simony et al. (2016)](https://doi.org/10.1038/ncomms12141). A description of the dataset is as follows:\n",
    "\n",
    ">18 native English speakers were scanned (15 females, ages: 18–31), corresponding to the replication dataset from the Pieman study.  \n",
    ">Stimuli for the experiment were generated from a 7 min real life story ([\"Pie Man\", Jim O'Grady](https://www.youtube.com/watch?v=3nZzSUDECLo)) recorded at a live storytelling performance ([\"The Moth\" storytelling event](https://themoth.org/), New York City). Subjects listened to the story from beginning to end (intact condition).\n",
    ">In addition, subjects listened to scrambled versions of the story, which were generated by dividing the original stimulus into segments of different timescales (paragraphs and words) and then permuting the order of these segments. To generate the scrambled stimuli, the story was segmented manually by identifying the end points of each word and paragraph. Two adjacent short words were assigned to a single segment in cases where we could not separate them. Following segmentation, the intact story was scrambled at two timescales: short—‘words’ (W; 608 words, 0.7±0.5 s each) and long—‘paragraphs’ (P; 11 paragraphs, 38.1±17.6 s each). Laughter and applause were classified as single word events (4.4% of the words). Twelve seconds of neutral music and 3 s of silence preceded, and 15 s of silence followed, each playback in all conditions. These music and silence periods were discarded from all analyses.\n",
    "\n",
    "More details about the experiment may be accessed in the methods section of the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Data File Preparation <a id=\"data_prep_isc\"></a>\n",
    "\n",
    "\n",
    "**Loading and preparing the data:**\n",
    "\n",
    "BrainIAK has methods to efficiently load data. We have used some of these functions in previous notebooks.\n",
    "\n",
    "> *load_images:* reads data from all subjects in a list that you provide. This is like the function load_images_from_dir but here we specify the names manually. \n",
    "\n",
    "> *load_boolean_mask:* Create a binary mask from a brain volume\n",
    "\n",
    "> *mask_images:* Loads the brain images and masks them with the mask provided\n",
    "\n",
    "> *image.MaskedMultiSubjectData.from_masked_images:* Creates a list of arrays, with each item in the list corresponding to one subject's data. This data format is accepted by the BrainIAK ISC and ISFC function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up experiment metadata\n",
    "\n",
    "from utils import pieman2_dir, results_path\n",
    "print('Data directory is: %s' % pieman2_dir)\n",
    "\n",
    "dir_mask = os.path.join(pieman2_dir, 'masks/')\n",
    "mask_name = os.path.join(dir_mask, 'avg152T1_gray_3mm.nii.gz')\n",
    "all_task_names = ['word', 'intact1']\n",
    "all_task_des = ['word level scramble', 'intact story']\n",
    "n_subjs_total = 18\n",
    "group_assignment_dict = {task_name: i for i, task_name in enumerate(all_task_names)}\n",
    "\n",
    "# Where do you want to store the data\n",
    "dir_out = results_path + 'isc/'\n",
    "if not os.path.exists(dir_out):\n",
    "    os.makedirs(dir_out)\n",
    "    print('Dir %s created ' % dir_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "\n",
    "We provide helper functions to load the data.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<strong>Memory limits</strong> Be aware this is going to be run on 18 participants and may push the limits of your memory and computational resources if you are on a laptop. If you want to run it on fewer participants to protect memory, change `n_subjs` to be lower (e.g. 10); however, the anticipated results may not generalize to lower sample sizes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reduce the number of subjects per condition to make this notebook faster \n",
    "upper_limit_n_subjs = 18\n",
    "\n",
    "def get_file_names(data_dir_, task_name_, verbose = False):\n",
    "    \"\"\"\n",
    "    Get all the participant file names\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dir_ [str]: the data root dir\n",
    "    task_name_ [str]: the name of the task \n",
    "    \n",
    "    Return\n",
    "    ----------\n",
    "    fnames_ [list]: file names for all subjs\n",
    "    \"\"\"\n",
    "    c_ = 0 \n",
    "    fnames_ = []\n",
    "    # Collect all file names \n",
    "    for subj in range(1, n_subjs_total): \n",
    "        fname = os.path.join(\n",
    "            data_dir_, 'sub-%.3d/func/sub-%.3d-task-%s.nii.gz' % (subj, subj, task_name_))\n",
    "        \n",
    "        # If the file exists\n",
    "        if os.path.exists(fname):\n",
    "            \n",
    "            # Add to the list of file names \n",
    "            fnames_.append(fname)\n",
    "            if verbose: \n",
    "                print(fname)\n",
    "            c_+= 1\n",
    "            if c_ >= upper_limit_n_subjs: \n",
    "                break\n",
    "    return fnames_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"load brain template\"\"\"\n",
    "\n",
    "# Load the brain mask\n",
    "brain_mask = io.load_boolean_mask(mask_name)\n",
    "\n",
    "# Get the list of nonzero voxel coordinates\n",
    "coords = np.where(brain_mask)\n",
    "\n",
    "# Load the brain nii image\n",
    "brain_nii = nib.load(mask_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"load bold data\"\"\"\n",
    "\n",
    "# load the functional data \n",
    "fnames = {}\n",
    "images = {}\n",
    "masked_images = {}\n",
    "bold = {}\n",
    "group_assignment = []\n",
    "n_subjs = {}\n",
    "\n",
    "for task_name in all_task_names: \n",
    "    fnames[task_name] = get_file_names(pieman2_dir, task_name)\n",
    "    images[task_name] = io.load_images(fnames[task_name]) \n",
    "    masked_images[task_name] = image.mask_images(images[task_name], brain_mask) \n",
    "    # Concatenate all of the masked images across participants  \n",
    "    bold[task_name] = image.MaskedMultiSubjectData.from_masked_images(\n",
    "        masked_images[task_name], len(fnames[task_name])\n",
    "    )\n",
    "    # Convert nans into zeros\n",
    "    bold[task_name][np.isnan(bold[task_name])] = 0\n",
    "    # compute the group assignment label \n",
    "    n_subjs_this_task = np.shape(bold[task_name])[-1]\n",
    "    group_assignment += list(\n",
    "        np.repeat(group_assignment_dict[task_name], n_subjs_this_task)\n",
    "    )\n",
    "    n_subjs[task_name] = np.shape(bold[task_name])[-1]\n",
    "    print('Data loaded: {} \\t shape: {}' .format(task_name, np.shape(bold[task_name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:**<a id=\"ex1\"></a> Inspect the data and report on the following details.\n",
    "- Brain template \n",
    " - Report the shape of `brain_nii`, `brain_mask`\n",
    " - Visualize `brain_nii` and `brain_mask` by plotting the 30th slice along the Z dimension.\n",
    " - Describe what `coords` refers to  \n",
    " - Visualize `coords` with a 3d plot. For this, only plot every 10th point, otherwise the plot will be slow to load. \n",
    "- Brain data \n",
    " - Inspect the shape of `bold`. How many subjects do we have for each task condition? Do different subjects have the same number of TRs/voxels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Insert code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Compute ISC <a id=\"isc_compute\"></a>\n",
    "\n",
    "ISC is the correlation of each voxel's time series for a participant with the corresponding (anatomically aligned) voxel time series in the average of the other participants' brains. BrainIAK has functions for computing ISC by feeding in the concatenated participant data. \n",
    "\n",
    "This will take about 10 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run ISC, loop over conditions \n",
    "isc_maps = {}\n",
    "for task_name in all_task_names:\n",
    "    isc_maps[task_name] = isc(bold[task_name], pairwise=False)\n",
    "    print('Shape of %s condition:' % task_name, np.shape(isc_maps[task_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of ISC is a voxel by participant matrix (showing the result of each individual with the group). Below we will visualize the ISC matrix for one participant and condition back on to the brain to see where activity is correlated between participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set params \n",
    "subj_id = 0\n",
    "task_name = 'intact1'\n",
    "save_data = False\n",
    "\n",
    "# Make the ISC output a volume\n",
    "isc_vol = np.zeros(brain_nii.shape)\n",
    "# Map the ISC data for the first participant into brain space\n",
    "isc_vol[coords] = isc_maps[task_name][subj_id, :]\n",
    "# make a nii image of the isc map \n",
    "isc_nifti = nib.Nifti1Image(isc_vol, brain_nii.affine, brain_nii.header)\n",
    "\n",
    "# Save the ISC data as a volume\n",
    "if save_data: \n",
    "    isc_map_path = os.path.join(dir_out, 'ISC_%s_sub%.2d.nii.gz' % (task_name, subj_id))\n",
    "    nib.save(isc_nifti, isc_map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the data as a statmap\n",
    "threshold = .2\n",
    "\n",
    "f, ax = plt.subplots(1,1, figsize = (12, 5))\n",
    "plotting.plot_stat_map(\n",
    "    isc_nifti, \n",
    "    threshold=threshold, \n",
    "    axes=ax\n",
    ")\n",
    "ax.set_title('ISC map for subject {}, task = {}' .format(subj_id,task_name)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** <a id=\"ex2\"></a> Visualize the averaged ISC map (averaged across participants) for each task. \n",
    "- Make the averaged ISC map for the two conditions (intact, word-scrambled). \n",
    "- Visualize them using `plotting.plot_stat_map`. \n",
    "\n",
    "Make sure to compare the two maps using the same xyz cut, threshold and vmax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis was performed in volumetric space; however, nilearn makes it easy to compare this data in surface space (assuming the alignment to MNI standard is excellent). Here's an example of surface plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set some plotting params \n",
    "subj_id = 0 \n",
    "task_name = 'intact1'\n",
    "threshold = .2 \n",
    "view = 'medial'\n",
    "\n",
    "# get a surface\n",
    "fsaverage = datasets.fetch_surf_fsaverage5()\n",
    "\n",
    "# Make the ISC output a volume\n",
    "isc_vol = np.zeros(brain_nii.shape)\n",
    "# Map the ISC data for the first participant into brain space\n",
    "isc_vol[coords] = isc_maps[task_name][subj_id, :]\n",
    "# make a nii image of the isc map \n",
    "isc_intact_1subj = nib.Nifti1Image(isc_vol, brain_nii.affine, brain_nii.header)\n",
    "\n",
    "# make \"texture\" \n",
    "texture = surface.vol_to_surf(isc_intact_1subj, fsaverage.pial_left) \n",
    "\n",
    "# plot \n",
    "title_text = ('Avg ISC map, {} for one participant'.format(task_name))\n",
    "surf_map = plotting.plot_surf_stat_map(\n",
    "    fsaverage.infl_left, texture, \n",
    "    hemi='left', view=view, \n",
    "    title= title_text, \n",
    "    threshold=threshold, cmap='RdYlBu_r', \n",
    "    colorbar=True,\n",
    "    bg_map=fsaverage.sulc_left)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** <a id=\"ex3\"></a> Visualize the averaged ISC map using surface plot. \n",
    "- Visualize the average ISC maps using `plotting.plot_surf_stat_map` for:\n",
    "    - both conditions\n",
    "    - both `medial` view and `lateral` views \n",
    "    \n",
    "Make sure you are using the same threshold and vmax for all plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4:** <a id=\"ex4\"></a> Compare the averaged ISC map for the two task conditions. What are some brain regions showing stronger correlation in the intact story condition (vs. the word-level scramble condition)? What does this tell us about the processing of language? \n",
    "\n",
    "Hint: The following [paper](https://doi.org/10.1523/JNEUROSCI.3684-10.2011) this work comes from will help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 ISC with statistical tests  <a id=\"isc_stats\"></a>\n",
    "\n",
    "BrainIAK provides several nonparametric statistical tests for ISC analysis ([Nastase et al., 2019](https://doi.org/10.1101/600114)). Nonparametric tests are preferred due to the inherent correlation structure across ISC values—each subject contributes to the ISC of other subjects, violating assumptions of independence required for standard parametric tests (e.g., t-test, ANOVA). We will use the permutation test below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Permutation test\n",
    "Permutation tests are used to compute a null distribution of values. We have used permutation tests in previous notebooks and the steps outlined here are similar to what was done in prior notebooks with one small change, incorporating the group of subjects to compute the ISC:\n",
    "\n",
    "1. Prepare the data. Here we have two conditions (intact and word_scramble), so we compute ISC for both conditions and concatenate the data for these two conditions for all subjects.  \n",
    "> We use leave-one-subject-out (`pairwise=False`) to compute ISC and then use these correlations `isc_maps_all_tasks` to compute statistics.  \n",
    "\n",
    "2. We are going to permute the condition label for each subject to simulate the randomization of conditions. To do this, we first need to assign subjects to the correct experimental conditions that they were in. We have prepared such a list of assignments when we loaded the data and stored the information in the variable: `group_assignment`.\n",
    " \n",
    "3. The next steps are executed internally in BrainIAK in the function `permutation_isc`:    \n",
    "> - For each permutation iteration: \n",
    ">> - BrainIAK permutes the group assignment for each subject.  \n",
    ">> - A mean of the ISC values is then computed for this shuffled \n",
    "group for each condition.   \n",
    ">> -  A difference of group means is computed between each condition.  \n",
    "> - The difference values for all iterations is collected and forms the null distribution.   \n",
    "4. Finally, we pick a threshold value that corresponds to `p` percent of this distribution.  \n",
    "\n",
    "`permutation_isc` returns the actual observed ISC values, p-values, and optionally the resampling distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate ISCs from both tasks\n",
    "isc_maps_all_tasks = np.vstack([isc_maps[task_name] for\n",
    "                                task_name in all_task_names])\n",
    "\n",
    "print('group_assignment: {}'.format(group_assignment))\n",
    "print('isc_maps_all_tasks: {}' .format(np.shape(isc_maps_all_tasks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# permutation testing\n",
    "n_permutations = 1000\n",
    "summary_statistic='mean'\n",
    "\n",
    "observed, p, distribution = permutation_isc(\n",
    "    isc_maps_all_tasks, \n",
    "    pairwise=False,\n",
    "    group_assignment=group_assignment, \n",
    "    summary_statistic=summary_statistic,\n",
    "    n_permutations=n_permutations\n",
    ")\n",
    "\n",
    "p = p.ravel()\n",
    "observed = observed.ravel()\n",
    "\n",
    "print('observed:{}'.format(np.shape(observed)))\n",
    "print('p:{}'.format(np.shape(p)))\n",
    "print('distribution: {}'.format(np.shape(distribution)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5:** <a id=\"ex5\"></a> Interpret the results from the permutation test. \n",
    "\n",
    "- What's the logic of the permutation test? \n",
    "- What are the outputs `observed`, `p`, `distribution` \n",
    "- Visualize the correlation contrast map (e.g. intact > word-level scramble) with a significance criterion (e.g. p < .005). Which region(s) showed higher ISC under the chosen contrast? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ISFC  <a id=\"isfc\"></a>\n",
    "\n",
    "The goal of ISFC is to find coupling between brain regions across participants. For example the angular gyrus in subject 1 could be correlated to the pre-frontal cortex in subject 2, if they share some cognitive state. For completely random cognitive states across these two subjects, the correlation should be zero. ISFC helps us identify such commonalities across subjects.\n",
    "\n",
    "In this section, we will compare functional connectivity vs. ISFC on the Pieman data. Whereas FC is computed within individuals, ISFC is computed between individuals. Hence the only correlations that should be robust in ISFC are those that are present across individuals. At the end of the exercises, you will qualitatively replicate [Simony et al. (2016)](https://doi.org/10.1038/ncomms12141), showing that ISFC is sensitive to the cognitive state of the participants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Parcel the data  <a id=\"isfc_parcel\"></a>\n",
    "\n",
    "ISFC in voxel space is very computationally intensive, so for this notebook we will divide the brain into a smaller number of parcels. We are going to use predefined ROI masks to select the voxels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load a parcel\n",
    "atlas = datasets.fetch_atlas_harvard_oxford('cort-maxprob-thr25-2mm', symmetric_split=True)\n",
    "plotting.plot_roi(atlas.maps, title='the harvard-oxford parcel')\n",
    "\n",
    "n_regions = len(atlas.labels)-1 # rm background region \n",
    "n_TRs = np.shape(bold[task_name])[0]\n",
    "\n",
    "print('number of voxels:\\t {}'.format(np.shape(bold[task_name][1])))\n",
    "print('number of parcels:\\t {}'.format(n_regions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the bold data into ROI parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get a masker for the atlas \n",
    "masker_ho = NiftiLabelsMasker(labels_img=atlas.maps)\n",
    "\n",
    "# Transform the data to the parcel space\n",
    "bold_ho = {\n",
    "    task_name:np.zeros((n_TRs, n_regions, n_subjs[task_name])) \n",
    "    for task_name in all_task_names}\n",
    "\n",
    "# Collect all data \n",
    "row_has_nan = np.zeros(shape=(n_regions,), dtype=bool)\n",
    "for task_name in all_task_names:\n",
    "    for subj_id in range(n_subjs[task_name]):\n",
    "        \n",
    "        # get the data for task t, subject s \n",
    "        nii_t_s = nib.load(fnames[task_name][subj_id])\n",
    "        bold_ho[task_name][:,:,subj_id] = masker_ho.fit_transform(nii_t_s)\n",
    "        \n",
    "        # figure out missing rois\n",
    "        row_has_nan_ = np.any(np.isnan(bold_ho[task_name][:,:,subj_id]),axis=0)\n",
    "        row_has_nan[row_has_nan_] = True                \n",
    "\n",
    "# Figure out which ROI has missing values\n",
    "roi_select = np.logical_not(row_has_nan)\n",
    "n_roi_select = np.sum(roi_select)\n",
    "rois_filtered = np.array(atlas.labels[1:])[roi_select]\n",
    "bold_ho_filtered = {\n",
    "    task_name:np.zeros((n_TRs, n_roi_select, n_subjs[task_name])) \n",
    "    for task_name in all_task_names\n",
    "}\n",
    "\n",
    "# Remove ROIs with missing values\n",
    "for task_name in all_task_names:\n",
    "    for subj_id in range(n_subjs[task_name]):\n",
    "        bold_ho_filtered[task_name][:,:,subj_id] = bold_ho[task_name][:,roi_select,subj_id]\n",
    "              \n",
    "print('ROI selected\\n {}'.format(rois_filtered))\n",
    "print('ROI removed due to missing values :( \\n {}'.format(np.array(atlas.labels[1:])[row_has_nan]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Compute FC and ISFC  <a id=\"fc_isfc\"></a>\n",
    "\n",
    "Here we compute FC and ISFC on the parcellated data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute FC\n",
    "fc_maps = {\n",
    "    task_name:np.zeros((n_roi_select,n_roi_select)) \n",
    "    for task_name in all_task_names\n",
    "}\n",
    "for task_name in all_task_names: \n",
    "    for subj_id in range(n_subjs[task_name]): \n",
    "        fc_maps[task_name] += np.corrcoef(\n",
    "            bold_ho_filtered[task_name][:,:,subj_id].T\n",
    "        ) / n_subjs[task_name]\n",
    "        np.fill_diagonal(fc_maps[task_name], np.nan)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute ISFC\n",
    "isfc_maps_ho = {}\n",
    "for task_name in all_task_names:\n",
    "    isfc_maps_ho[task_name] = isfc(data=bold_ho_filtered[task_name],\n",
    "                                   summary_statistic='median',\n",
    "                                   vectorize_isfcs=False)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6:** <a id=\"ex6\"></a> Visualize the FC/ISFC matrices, averaged across subjects\n",
    "\n",
    "- Use `imshow` to visualize the 4 correlation matrices: (FC vs. ISFC) x (word-level scrambled vs. intact story)\n",
    "- Mark the rows (or columns) with the ROI labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7:** <a id=\"ex7\"></a> Visualize FC/ISFC connectivity strength on glass brains \n",
    "\n",
    "- Use `plot_connectome` to visualize the 4 correlation matrices: (FC vs. ISFC) x (word-level scrabled vs. intact story)\n",
    "- Use common `edge_threshold` for all plots. \n",
    "\n",
    "*Hint:* The plot_connectome function takes as an input a correlation matrix (such as the FC one plotted above) and also a set of coordinates that define the XYZ coordinates that corresponds to each column/row of the correlation matrix. In order to get the coordinates of these ROIs, we recommend you use: `plotting.find_parcellation_cut_coords(atlas.maps)[roi_select]`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8:** <a id=\"ex8\"></a> Do FC maps look different across conditions? How about ISFC? And why? Hint: consult this [paper](https://doi.org/10.1038/ncomms12141)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Spatial pattern correlation across subjects <a id=\"spat_corr\"></a>\n",
    "\n",
    "\n",
    "### 4.1 Spatial inter-subject correlation  <a id=\"spatial_isc\"></a>\n",
    "\n",
    "<br>\n",
    "We can apply the idea of inter-subject analysis to RSA. So far, ISC is being computed between aligned pairs of voxels across time points and it is commonly referred to as temporal ISC. However, we could instead correlate between aligned pairs of time points across voxels. That is, how does the pattern of activity across voxels for one time point correlate with the average pattern of the other participants at that time point. By doing this for each time point, we can generate a time course of these correlations to observe the general ebb and flow of coupling in brain activity across participants. This can be done simply by transposing the voxel and time dimensions (for a 3-D matrix, this is accomplished with a 90 degree rotation). This is a simple [transposition](https://lihan.me/2018/01/numpy-reshape-and-transpose/). If we have data in the format: (TRs, voxels, subjects), we can use `data.transpose(1,0,2)`, where the indices refer to the dimensions of the array and we will have an array in the format (voxels, TRs, subjects)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the two task conditions with spatial ISC \n",
    "\n",
    "One way to compare the intact and word_scramble conditions is to plot the correlation values, by TR, for each condition. Again, we can use the same ISC functions from above after transposing the data matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get a list of ROIs. \n",
    "roi_mask_path = os.path.join(pieman2_dir,'masks','rois')\n",
    "all_roi_fpaths = glob.glob(os.path.join(roi_mask_path, '*.nii.gz'))\n",
    "\n",
    "# Collect all ROIs \n",
    "all_roi_names = []\n",
    "all_roi_nii = {}\n",
    "all_roi_masker = {}\n",
    "for roi_fpath in all_roi_fpaths:\n",
    "    \n",
    "    # Compute ROI name\n",
    "    roi_fname = os.path.basename(roi_fpath)\n",
    "    roi_name = roi_fname.split('.')[0]\n",
    "    all_roi_names.append(roi_name)\n",
    "    \n",
    "    # Load roi nii file \n",
    "    roi_nii = nib.load(roi_fpath)\n",
    "    all_roi_nii[roi_name] = roi_nii\n",
    "    \n",
    "    # Make roi maskers\n",
    "    all_roi_masker[roi_name] = NiftiMasker(mask_img=roi_nii)\n",
    "\n",
    "print('Path to all roi masks: {}'.format(roi_mask_path))    \n",
    "print('Here are all ROIs:\\n{}'.format(all_roi_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a function to load data for one ROI\n",
    "def load_roi_data(roi_name): \n",
    "    # Pick a roi masker\n",
    "    roi_masker = all_roi_masker[roi_name]    \n",
    "    \n",
    "    # Preallocate \n",
    "    bold_roi = {task_name:[] for i, task_name in enumerate(all_task_names)}\n",
    "    \n",
    "    # Gather data \n",
    "    for task_name in all_task_names:\n",
    "        for subj_id in range(n_subjs[task_name]):\n",
    "            \n",
    "            # Get the data for task t, subject s \n",
    "            nii_t_s = nib.load(fnames[task_name][subj_id])\n",
    "            bold_roi[task_name].append(roi_masker.fit_transform(nii_t_s))\n",
    "            \n",
    "        # Reformat the data to std form \n",
    "        bold_roi[task_name] = np.transpose(np.array(bold_roi[task_name]), [1,2,0])\n",
    "    return bold_roi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute spatial ISC on some ROIs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roi_selected = ['dPCC', 'vPCUN', 'V1']\n",
    "roi_selected_names = ['dorsal posterior cingulate cortex', 'ventral precuneus', 'primary visual cortex']\n",
    "\n",
    "# compute sISC for all ROIs \n",
    "iscs_roi_selected = []\n",
    "for j, roi_name in enumerate(roi_selected):\n",
    "    print(j, roi_name)\n",
    "    \n",
    "    # Load data \n",
    "    bold_roi = load_roi_data(roi_name)\n",
    "    \n",
    "    # Compute isc \n",
    "    iscs_roi = {}\n",
    "    for task_name in all_task_names: \n",
    "        iscs_roi[task_name] = isc(np.transpose(bold_roi[task_name], [1,0,2]))\n",
    "        \n",
    "    iscs_roi_selected.append(iscs_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the spatial ISC over time\n",
    "col_pal = sns.color_palette(palette='colorblind', n_colors=len(all_task_names))\n",
    "ci = 95\n",
    "\n",
    "f, axes = plt.subplots(len(roi_selected), 1, figsize=(14, 5 * len(roi_selected)), sharex=True)\n",
    "\n",
    "# For each ROI\n",
    "for j, roi_name in enumerate(roi_selected):\n",
    "    # For each task \n",
    "    for i, task_name in enumerate(all_task_names): \n",
    "        sns.tsplot(\n",
    "            iscs_roi_selected[j][task_name], \n",
    "            color=col_pal[i], ci=ci, \n",
    "            ax=axes[j]\n",
    "        )\n",
    "    f.legend(all_task_des)\n",
    "    sns.despine()\n",
    "\n",
    "# Label the plot \n",
    "for j, roi_name in enumerate(roi_selected):\n",
    "    axes[j].axhline(0, color='black', linestyle='--', alpha=.3)\n",
    "    axes[j].set_ylabel('Linear correlation')\n",
    "    axes[j].set_title('Spatial inter-subject correlation, {}'. format(roi_selected_names[j]))\n",
    "    \n",
    "axes[-1].set_xlabel('TRs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9:**<a id=\"ex9\"></a> Interpret the spatial ISC results you observed above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Novel contribution:**<a id=\"novel\"></a> be creative and make one new discovery by adding an analysis, visualization, or optimization.\n",
    "\n",
    "Here are some ideas: \n",
    "\n",
    "- The ISC package in BrainIAK supports other statistical tests. Study one of them, describe the logic behind it, and re-run the analysis with that test. \n",
    "- Conduct a sliding window spatial ISC analysis. \n",
    "- Perform some clustering on the ISFC matrices. Use the clustering (instead of the anatomical parcel) to re-analyze the data, and compare ISFC vs. FC across tasks. See [here](http://scikit-learn.org/stable/modules/clustering.html) for a good resource on clustering algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contributions<a id=\"contributions\"></a>\n",
    "\n",
    "E. Simony and U. Hasson for providing data  \n",
    "C. Baldassano and C. Chen provided initial code  \n",
    "M. Kumar, C. Ellis and N. Turk-Browne produced the initial notebook 4/4/18  \n",
    "S. Nastase enhanced the ISC brainiak module; added the section on statistical testing   \n",
    "Q. Lu added solutions; switched to S. Nastase's ISC module; replicated Lerner et al 2011 & Simony et al. 2016; added spatial ISC.   \n",
    "M. Kumar edits to section introductions and explanation on permutation test.  \n",
    "K.A. Norman provided suggestions on the overall content and made edits to this notebook.  \n",
    "C. Ellis incorporated edits from cmhn-s19  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
